{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train CNN Model 3 Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "11/11 [==============================] - 1s 26ms/step - loss: 1.1730 - accuracy: 0.4713 - val_loss: 1.2071 - val_accuracy: 0.3182\n",
      "Epoch 2/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1.0329 - accuracy: 0.7500 - val_loss: 1.1955 - val_accuracy: 0.4205\n",
      "Epoch 3/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.8814 - accuracy: 0.8190 - val_loss: 1.1774 - val_accuracy: 0.4432\n",
      "Epoch 4/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.6976 - accuracy: 0.8649 - val_loss: 1.1588 - val_accuracy: 0.4091\n",
      "Epoch 5/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.5359 - accuracy: 0.9080 - val_loss: 1.1426 - val_accuracy: 0.3636\n",
      "Epoch 6/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.4007 - accuracy: 0.9339 - val_loss: 1.1417 - val_accuracy: 0.3977\n",
      "Epoch 7/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.2904 - accuracy: 0.9655 - val_loss: 1.1669 - val_accuracy: 0.3864\n",
      "Epoch 8/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.2372 - accuracy: 0.9626 - val_loss: 1.2496 - val_accuracy: 0.4091\n",
      "Epoch 9/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.1761 - accuracy: 0.9885 - val_loss: 1.3840 - val_accuracy: 0.3750\n",
      "Epoch 10/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1521 - accuracy: 0.9914 - val_loss: 1.5116 - val_accuracy: 0.4318\n",
      "Epoch 11/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1358 - accuracy: 0.9971 - val_loss: 1.7672 - val_accuracy: 0.3977\n",
      "Epoch 12/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1206 - accuracy: 1.0000 - val_loss: 2.0458 - val_accuracy: 0.3977\n",
      "Epoch 13/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1141 - accuracy: 1.0000 - val_loss: 2.0249 - val_accuracy: 0.3977\n",
      "Epoch 14/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1073 - accuracy: 1.0000 - val_loss: 1.8483 - val_accuracy: 0.5114\n",
      "Epoch 15/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.1044 - accuracy: 1.0000 - val_loss: 1.9208 - val_accuracy: 0.4318\n",
      "Epoch 16/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.1012 - accuracy: 1.0000 - val_loss: 1.9305 - val_accuracy: 0.4545\n",
      "Epoch 17/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0973 - accuracy: 1.0000 - val_loss: 1.8403 - val_accuracy: 0.4773\n",
      "Epoch 18/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0941 - accuracy: 1.0000 - val_loss: 1.8387 - val_accuracy: 0.5000\n",
      "Epoch 19/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0933 - accuracy: 1.0000 - val_loss: 1.8763 - val_accuracy: 0.5455\n",
      "Epoch 20/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0891 - accuracy: 1.0000 - val_loss: 1.7881 - val_accuracy: 0.5682\n",
      "Epoch 21/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0867 - accuracy: 1.0000 - val_loss: 1.6901 - val_accuracy: 0.6136\n",
      "Epoch 22/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0845 - accuracy: 1.0000 - val_loss: 1.6088 - val_accuracy: 0.6591\n",
      "Epoch 23/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0824 - accuracy: 1.0000 - val_loss: 1.5313 - val_accuracy: 0.6932\n",
      "Epoch 24/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0801 - accuracy: 1.0000 - val_loss: 1.4615 - val_accuracy: 0.6932\n",
      "Epoch 25/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0776 - accuracy: 1.0000 - val_loss: 1.3898 - val_accuracy: 0.6932\n",
      "Epoch 26/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0777 - accuracy: 1.0000 - val_loss: 1.4478 - val_accuracy: 0.7045\n",
      "Epoch 27/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0745 - accuracy: 1.0000 - val_loss: 1.2284 - val_accuracy: 0.7273\n",
      "Epoch 28/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0718 - accuracy: 1.0000 - val_loss: 1.1526 - val_accuracy: 0.7500\n",
      "Epoch 29/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0695 - accuracy: 1.0000 - val_loss: 1.1181 - val_accuracy: 0.7273\n",
      "Epoch 30/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0673 - accuracy: 1.0000 - val_loss: 0.9668 - val_accuracy: 0.7955\n",
      "Epoch 31/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0651 - accuracy: 1.0000 - val_loss: 0.8408 - val_accuracy: 0.8068\n",
      "Epoch 32/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0637 - accuracy: 1.0000 - val_loss: 0.6754 - val_accuracy: 0.7841\n",
      "Epoch 33/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0614 - accuracy: 1.0000 - val_loss: 0.5547 - val_accuracy: 0.8182\n",
      "Epoch 34/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0597 - accuracy: 1.0000 - val_loss: 0.5386 - val_accuracy: 0.8182\n",
      "Epoch 35/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0577 - accuracy: 1.0000 - val_loss: 0.4389 - val_accuracy: 0.8295\n",
      "Epoch 36/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0559 - accuracy: 1.0000 - val_loss: 0.3247 - val_accuracy: 0.8523\n",
      "Epoch 37/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0545 - accuracy: 1.0000 - val_loss: 0.2282 - val_accuracy: 0.9205\n",
      "Epoch 38/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0526 - accuracy: 1.0000 - val_loss: 0.1586 - val_accuracy: 0.9773\n",
      "Epoch 39/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0509 - accuracy: 1.0000 - val_loss: 0.1195 - val_accuracy: 0.9773\n",
      "Epoch 40/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0493 - accuracy: 1.0000 - val_loss: 0.0859 - val_accuracy: 0.9773\n",
      "Epoch 41/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0480 - accuracy: 1.0000 - val_loss: 0.0670 - val_accuracy: 1.0000\n",
      "Epoch 42/100\n",
      "11/11 [==============================] - 0s 12ms/step - loss: 0.0465 - accuracy: 1.0000 - val_loss: 0.0561 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0451 - accuracy: 1.0000 - val_loss: 0.0499 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0437 - accuracy: 1.0000 - val_loss: 0.0466 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0424 - accuracy: 1.0000 - val_loss: 0.0441 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0410 - accuracy: 1.0000 - val_loss: 0.0421 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0399 - accuracy: 1.0000 - val_loss: 0.0404 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0385 - accuracy: 1.0000 - val_loss: 0.0391 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0373 - accuracy: 1.0000 - val_loss: 0.0375 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0361 - accuracy: 1.0000 - val_loss: 0.0360 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0348 - accuracy: 1.0000 - val_loss: 0.0347 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0340 - accuracy: 1.0000 - val_loss: 0.0335 - val_accuracy: 1.0000\n",
      "Epoch 53/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0330 - accuracy: 1.0000 - val_loss: 0.0324 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0320 - accuracy: 1.0000 - val_loss: 0.0313 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0309 - accuracy: 1.0000 - val_loss: 0.0303 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0301 - accuracy: 1.0000 - val_loss: 0.0293 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0288 - accuracy: 1.0000 - val_loss: 0.0284 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0279 - accuracy: 1.0000 - val_loss: 0.0275 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0273 - accuracy: 1.0000 - val_loss: 0.0266 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0262 - accuracy: 1.0000 - val_loss: 0.0257 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0254 - accuracy: 1.0000 - val_loss: 0.0249 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0246 - accuracy: 1.0000 - val_loss: 0.0241 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0240 - accuracy: 1.0000 - val_loss: 0.0234 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0231 - accuracy: 1.0000 - val_loss: 0.0227 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0226 - accuracy: 1.0000 - val_loss: 0.0219 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0217 - accuracy: 1.0000 - val_loss: 0.0212 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0210 - accuracy: 1.0000 - val_loss: 0.0206 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0204 - accuracy: 1.0000 - val_loss: 0.0200 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0197 - accuracy: 1.0000 - val_loss: 0.0193 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0190 - accuracy: 1.0000 - val_loss: 0.0187 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0184 - accuracy: 1.0000 - val_loss: 0.0182 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 0.0176 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0173 - accuracy: 1.0000 - val_loss: 0.0171 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0169 - accuracy: 1.0000 - val_loss: 0.0166 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 0.0161 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "11/11 [==============================] - 0s 10ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 0.0156 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 0.0151 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 0.0146 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0143 - accuracy: 1.0000 - val_loss: 0.0142 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0139 - accuracy: 1.0000 - val_loss: 0.0137 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0137 - accuracy: 1.0000 - val_loss: 0.0133 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.0129 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0127 - accuracy: 1.0000 - val_loss: 0.0125 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.0122 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0115 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0110 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0107 - accuracy: 1.0000 - val_loss: 0.0105 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0103 - accuracy: 1.0000 - val_loss: 0.0102 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0100 - accuracy: 1.0000 - val_loss: 0.0099 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0099 - accuracy: 1.0000 - val_loss: 0.0096 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0095 - accuracy: 1.0000 - val_loss: 0.0093 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0093 - accuracy: 1.0000 - val_loss: 0.0091 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 0.0088 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.0086 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0085 - accuracy: 1.0000 - val_loss: 0.0083 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 0.0081 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.0081 - accuracy: 1.0000 - val_loss: 0.0079 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 0.0077 - val_accuracy: 1.0000\n",
      "5/5 - 0s - loss: 0.0719 - accuracy: 0.9932 - 19ms/epoch - 4ms/step\n",
      "\n",
      "Test accuracy: 0.9931507110595703\n",
      "19/19 [==============================] - 0s 2ms/step\n",
      "19/19 [==============================] - 0s 1ms/step\n",
      "Confusion Matrix:\n",
      "        Predicted 0  Predicted 1  Predicted 2\n",
      "True 0           83           94           17\n",
      "True 1           38          144           12\n",
      "True 2           39           83           72\n",
      "Precision: 0.5600731393232781\n",
      "F1 Score: 0.5054284826211763\n",
      "5/5 - 0s - loss: 0.0719 - accuracy: 0.9932 - 19ms/epoch - 4ms/step\n",
      "\n",
      "Test accuracy: 0.9931507110595703\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import librosa\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "DATA_PATH = \"/Users/danielporras/Musica/musica_analysis/models/data.json_3_classes\"\n",
    "\n",
    "def extract_features(file_path):\n",
    "    # Your feature extraction code remains the same here...\n",
    "    pass\n",
    "\n",
    "def add_noise(X_train):\n",
    "    noise_factor = 0.005 * np.random.randn(*X_train.shape)\n",
    "    X_train_noisy = X_train + noise_factor\n",
    "    return X_train_noisy\n",
    "\n",
    "def load_data(data_path):\n",
    "    with open(data_path, \"r\") as fp:\n",
    "        data = json.load(fp)\n",
    "\n",
    "    X = np.array(data[\"features\"])\n",
    "    y = np.array(data[\"labels\"])\n",
    "\n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    # Apply SMOTE\n",
    "    smote = SMOTE()\n",
    "    X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "    return X_resampled, y_resampled, scaler\n",
    "\n",
    "def prepare_datasets(test_size, validation_size):\n",
    "    X, y, scaler = load_data(DATA_PATH)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "    X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=validation_size)\n",
    "\n",
    "    # Add noise to the training set\n",
    "    X_train = add_noise(X_train)\n",
    "\n",
    "    # Reshape for Conv1D\n",
    "    X_train = X_train[..., np.newaxis]\n",
    "    X_validation = X_validation[..., np.newaxis]\n",
    "    X_test = X_test[..., np.newaxis]\n",
    "\n",
    "    return X_train, X_validation, X_test, y_train, y_validation, y_test, scaler\n",
    "\n",
    "def build_model(input_shape):\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # 1D Convolutional layers\n",
    "    model.add(layers.Conv1D(64, kernel_size=3, activation='relu', input_shape=input_shape, padding='same'))\n",
    "    model.add(layers.MaxPooling1D(pool_size=2, padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    model.add(layers.Conv1D(128, kernel_size=3, activation='relu', padding='same'))\n",
    "    model.add(layers.MaxPooling1D(pool_size=2, padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "\n",
    "    # Recurrent layer\n",
    "    model.add(layers.LSTM(64, return_sequences=False))\n",
    "\n",
    "    # Dense layers\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(512, activation='relu', kernel_regularizer=regularizers.l2(0.001)))\n",
    "    model.add(layers.Dropout(0.3))\n",
    "    model.add(layers.Dense(3, activation='softmax'))  # Adjusted to 3 classes\n",
    "\n",
    "    return model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load the data\n",
    "    X_train, X_validation, X_test, y_train, y_validation, y_test, scaler = prepare_datasets(0.25, 0.2)\n",
    "\n",
    "    input_shape = (X_train.shape[1], X_train.shape[2])\n",
    "\n",
    "    # Build the model\n",
    "    model = build_model(input_shape)\n",
    "\n",
    "    # Compile the model\n",
    "    optimiser = tf.keras.optimizers.Adam(learning_rate=0.0005)\n",
    "    model.compile(optimizer=optimiser,\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    # Train the model\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_validation, y_validation),\n",
    "                        epochs=100, batch_size=32)\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "    print('\\nTest accuracy:', test_acc)\n",
    "\n",
    "    # Compute predictions\n",
    "    y_prob = model.predict(X)\n",
    "    y_pred = np.argmax(y_prob, axis=1)\n",
    "\n",
    "    # Flatten y back to 1D\n",
    "    y = y.flatten()\n",
    "\n",
    "    # Compute predictions\n",
    "    y_prob = model.predict(X)\n",
    "    y_pred = np.argmax(y_prob, axis=1)\n",
    "\n",
    "    # Create confusion matrix\n",
    "    cm = confusion_matrix(y, y_pred, labels=[0, 1, 2])\n",
    "\n",
    "    # Display confusion matrix\n",
    "    cm_df = pd.DataFrame(cm, index=[f'True {i}' for i in range(3)], columns=[f'Predicted {i}' for i in range(3)])\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm_df)\n",
    "\n",
    "    # Compute precision and F1 score\n",
    "    precision = precision_score(y, y_pred, average='weighted')\n",
    "    print(f'Precision: {precision}')\n",
    "\n",
    "    f1 = f1_score(y, y_pred, average='weighted')\n",
    "    print(f'F1 Score: {f1}')\n",
    "\n",
    "\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "    print('\\nTest accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### json_3_classes_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "11/11 [==============================] - 1s 55ms/step - loss: 1.7545 - accuracy: 0.4665 - val_loss: 1.1718 - val_accuracy: 0.7791\n",
      "Epoch 2/30\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 1.0785 - accuracy: 0.6356 - val_loss: 0.8447 - val_accuracy: 0.7442\n",
      "Epoch 3/30\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.8087 - accuracy: 0.7988 - val_loss: 0.6896 - val_accuracy: 0.9070\n",
      "Epoch 4/30\n",
      "11/11 [==============================] - 1s 51ms/step - loss: 0.5496 - accuracy: 0.9009 - val_loss: 0.4863 - val_accuracy: 0.9419\n",
      "Epoch 5/30\n",
      "11/11 [==============================] - 1s 52ms/step - loss: 0.4236 - accuracy: 0.9534 - val_loss: 0.3278 - val_accuracy: 0.9767\n",
      "Epoch 6/30\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 0.3203 - accuracy: 0.9767 - val_loss: 0.2579 - val_accuracy: 1.0000\n",
      "Epoch 7/30\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 0.2642 - accuracy: 0.9913 - val_loss: 0.2317 - val_accuracy: 1.0000\n",
      "Epoch 8/30\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.2353 - accuracy: 0.9913 - val_loss: 0.2254 - val_accuracy: 1.0000\n",
      "Epoch 9/30\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.2263 - accuracy: 0.9942 - val_loss: 0.2017 - val_accuracy: 1.0000\n",
      "Epoch 10/30\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 0.2140 - accuracy: 0.9942 - val_loss: 0.2252 - val_accuracy: 0.9767\n",
      "Epoch 11/30\n",
      "11/11 [==============================] - 0s 46ms/step - loss: 0.1933 - accuracy: 1.0000 - val_loss: 0.1950 - val_accuracy: 0.9767\n",
      "Epoch 12/30\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 0.1766 - accuracy: 1.0000 - val_loss: 0.1804 - val_accuracy: 0.9767\n",
      "Epoch 13/30\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 0.1646 - accuracy: 0.9971 - val_loss: 0.1691 - val_accuracy: 0.9767\n",
      "Epoch 14/30\n",
      "11/11 [==============================] - 0s 46ms/step - loss: 0.1517 - accuracy: 1.0000 - val_loss: 0.1603 - val_accuracy: 1.0000\n",
      "Epoch 15/30\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.1482 - accuracy: 0.9971 - val_loss: 0.1446 - val_accuracy: 1.0000\n",
      "Epoch 16/30\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 0.1594 - accuracy: 0.9971 - val_loss: 0.1557 - val_accuracy: 1.0000\n",
      "Epoch 17/30\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.1481 - accuracy: 0.9971 - val_loss: 0.1646 - val_accuracy: 0.9767\n",
      "Epoch 18/30\n",
      "11/11 [==============================] - 0s 46ms/step - loss: 0.1451 - accuracy: 0.9971 - val_loss: 0.1376 - val_accuracy: 1.0000\n",
      "Epoch 19/30\n",
      "11/11 [==============================] - 1s 49ms/step - loss: 0.1311 - accuracy: 1.0000 - val_loss: 0.1379 - val_accuracy: 0.9767\n",
      "Epoch 20/30\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 0.1240 - accuracy: 0.9971 - val_loss: 0.1187 - val_accuracy: 1.0000\n",
      "Epoch 21/30\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 0.1137 - accuracy: 1.0000 - val_loss: 0.1189 - val_accuracy: 1.0000\n",
      "Epoch 22/30\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 0.1085 - accuracy: 1.0000 - val_loss: 0.1089 - val_accuracy: 1.0000\n",
      "Epoch 23/30\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 0.0993 - accuracy: 1.0000 - val_loss: 0.1021 - val_accuracy: 1.0000\n",
      "Epoch 24/30\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.0940 - accuracy: 1.0000 - val_loss: 0.1071 - val_accuracy: 0.9767\n",
      "Epoch 25/30\n",
      "11/11 [==============================] - 0s 46ms/step - loss: 0.0878 - accuracy: 1.0000 - val_loss: 0.0911 - val_accuracy: 1.0000\n",
      "Epoch 26/30\n",
      "11/11 [==============================] - 1s 48ms/step - loss: 0.0835 - accuracy: 1.0000 - val_loss: 0.0936 - val_accuracy: 1.0000\n",
      "Epoch 27/30\n",
      "11/11 [==============================] - 0s 46ms/step - loss: 0.0800 - accuracy: 1.0000 - val_loss: 0.0866 - val_accuracy: 1.0000\n",
      "Epoch 28/30\n",
      "11/11 [==============================] - 1s 46ms/step - loss: 0.0765 - accuracy: 1.0000 - val_loss: 0.0966 - val_accuracy: 0.9767\n",
      "Epoch 29/30\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 0.0757 - accuracy: 1.0000 - val_loss: 0.0852 - val_accuracy: 1.0000\n",
      "Epoch 30/30\n",
      "11/11 [==============================] - 1s 47ms/step - loss: 0.0716 - accuracy: 1.0000 - val_loss: 0.1015 - val_accuracy: 0.9767\n",
      "5/5 - 0s - loss: 0.0769 - accuracy: 0.9925 - 54ms/epoch - 11ms/step\n",
      "\n",
      "Test accuracy: 0.9925373196601868\n",
      "5/5 [==============================] - 0s 9ms/step\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "happy_exciting       0.98      1.00      0.99        45\n",
      "    heavy_rock       1.00      0.97      0.99        38\n",
      "sad_reflective       1.00      1.00      1.00        51\n",
      "\n",
      "      accuracy                           0.99       134\n",
      "     macro avg       0.99      0.99      0.99       134\n",
      "  weighted avg       0.99      0.99      0.99       134\n",
      "\n",
      "Confusion Matrix:\n",
      "[[45  0  0]\n",
      " [ 1 37  0]\n",
      " [ 0  0 51]]\n",
      "INFO:tensorflow:Assets written to: /Users/danielporras/Musica/music_x/best_model.h8/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: /Users/danielporras/Musica/music_x/best_model.h8/assets\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras import layers, models, regularizers\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import precision_score, f1_score, classification_report\n",
    "\n",
    "DATA_PATH = \"/Users/danielporras/Musica/musica_analysis/models/data.json_3_classes_2\"\n",
    "\n",
    "\n",
    "def add_noise(X_train):\n",
    "    noise_factor = 0.005 * np.random.randn(*X_train.shape)\n",
    "    X_train_noisy = X_train + noise_factor\n",
    "    return X_train_noisy\n",
    "\n",
    "def load_data(data_path):\n",
    "    with open(data_path, \"r\") as fp:\n",
    "        data = json.load(fp)\n",
    "\n",
    "    X = np.array(data[\"features\"])\n",
    "    y = np.array(data[\"labels\"])\n",
    "\n",
    "    # Reshape for Conv2D: Add a channel dimension\n",
    "    X = X.reshape(X.shape[0], 40, 174, 1)  # Adjust shape to match the CNN input\n",
    "\n",
    "    # Standardize features\n",
    "    # It's crucial to fit the scaler on the training set only to avoid data leakage\n",
    "    # Splitting data first\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "    scaler = StandardScaler().fit(X_train.reshape(X_train.shape[0], -1))\n",
    "    \n",
    "    # Transform and then reshape back to original shape for both train and test sets\n",
    "    X_train = scaler.transform(X_train.reshape(X_train.shape[0], -1)).reshape(X_train.shape)\n",
    "    X_test = scaler.transform(X_test.reshape(X_test.shape[0], -1)).reshape(X_test.shape)\n",
    "\n",
    "    # Apply SMOTE on flattened X_train to avoid dimensionality issues\n",
    "    smote = SMOTE()\n",
    "    X_train_flat, y_train_resampled = smote.fit_resample(X_train.reshape(X_train.shape[0], -1), y_train)\n",
    "    X_train_resampled = X_train_flat.reshape(-1, 40, 174, 1)\n",
    "\n",
    "    return X_train_resampled, X_test, y_train_resampled, y_test, scaler\n",
    "\n",
    "def build_model(input_shape):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(3, activation='softmax')  # Adjusted to 3 classes\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    X_train, X_test, y_train, y_test, scaler = load_data(DATA_PATH)\n",
    "    input_shape = X_train.shape[1:]  # Input shape for Conv2D\n",
    "\n",
    "    model = build_model(input_shape)\n",
    "    history = model.fit(X_train, y_train, validation_split=0.2, epochs=30, batch_size=32)\n",
    "\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\n",
    "    print('\\nTest accuracy:', test_acc)\n",
    "\n",
    "        # Predict the probabilities for the test set\n",
    "    predictions_prob = model.predict(X_test)\n",
    "    # Convert these probabilities to class labels\n",
    "    predictions = np.argmax(predictions_prob, axis=1)\n",
    "\n",
    "    # Calculate and display the classification report\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, predictions, target_names=['happy_exciting', 'heavy_rock', 'sad_reflective']))\n",
    "\n",
    "    # Calculate and display the confusion matrix\n",
    "    print(\"Confusion Matrix:\")\n",
    "    cm = confusion_matrix(y_test, predictions)\n",
    "    print(cm)\n",
    "\n",
    "    # Save the model\n",
    "    model.save('/Users/danielporras/Musica/music_x/best_model.h8')\n",
    "\n",
    "    # Use the trained scaler to transform new data for predictions\n",
    "    # X_new_transformed = scaler.transform(X_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env_3_10",
   "language": "python",
   "name": "new_env_3_10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
