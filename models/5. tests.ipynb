{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import librosa\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Model h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the model\n",
    "loaded_model = load_model('/Users/danielporras/Musica/music_x/best_model.h8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class labels: ['Black' 'Blue' 'Gray' 'Green' 'Orange' 'Red' 'Sky Blue' 'Yellow']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assume 'labels' is a list of your labels\n",
    "labels = ['Red', 'Blue', 'Green', 'Yellow', 'Black', 'Gray', 'Sky Blue', 'Orange']\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(labels)\n",
    "\n",
    "print('Class labels:', encoder.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_songs(directory):\n",
    "    song_features = []\n",
    "    song_names = []  # List to store the names of the songs\n",
    "    \n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith('.mp3') or filename.endswith('.m4a'):  # Assuming the songs are in .mp3 or .m4a format\n",
    "            song_path = os.path.join(directory, filename)\n",
    "            mfccs = extract_features(song_path)\n",
    "            \n",
    "            if mfccs is not None:  # Only append features if mfccs could be computed\n",
    "                # Reshape the data to match the expected input shape\n",
    "                mfccs = np.reshape(mfccs, (26, 1, 1))\n",
    "                song_features.append(mfccs)\n",
    "                song_names.append(filename)  # Store the name of the song\n",
    "                \n",
    "    # Convert list to numpy array\n",
    "    song_features = np.array(song_features)\n",
    "\n",
    "    # Ensure the data has the correct shape\n",
    "    if len(song_features.shape) < 4:\n",
    "        # Add a dimension for the batch size\n",
    "        song_features = np.expand_dims(song_features, axis=0)\n",
    "\n",
    "    return song_features, song_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_path):\n",
    "    audio, sample_rate = librosa.load(file_path, res_type='kaiser_fast') \n",
    "    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=26)\n",
    "    mfccs_processed = np.mean(mfccs.T,axis=0)\n",
    "     \n",
    "    return mfccs_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_t/p3lht79d2_jd6gwjl515j1g40000gn/T/ipykernel_98076/3396950221.py:2: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  audio, sample_rate = librosa.load(file_path, res_type='kaiser_fast')\n",
      "/Users/danielporras/Musica/new_env_3_10/lib/python3.10/site-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/danielporras/Musica/new_env_3_10/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2440, in predict_function  *\n        return step_function(self, iterator)\n    File \"/Users/danielporras/Musica/new_env_3_10/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2425, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/danielporras/Musica/new_env_3_10/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2413, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/Users/danielporras/Musica/new_env_3_10/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2381, in predict_step\n        return self(x, training=False)\n    File \"/Users/danielporras/Musica/new_env_3_10/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/danielporras/Musica/new_env_3_10/lib/python3.10/site-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_14\" is incompatible with the layer: expected shape=(None, 40, 174, 1), found shape=(32, 26, 1, 1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m test_songs, test_song_names \u001b[38;5;241m=\u001b[39m load_and_preprocess_songs(test_dir)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Use the loaded model to make predictions\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mloaded_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_songs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Get the class with the highest probability\u001b[39;00m\n\u001b[1;32m     11\u001b[0m predicted_classes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(predictions, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/Musica/new_env_3_10/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/_t/p3lht79d2_jd6gwjl515j1g40000gn/T/__autograph_generated_filefvvrqg84.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/danielporras/Musica/new_env_3_10/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2440, in predict_function  *\n        return step_function(self, iterator)\n    File \"/Users/danielporras/Musica/new_env_3_10/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2425, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/danielporras/Musica/new_env_3_10/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2413, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/Users/danielporras/Musica/new_env_3_10/lib/python3.10/site-packages/keras/src/engine/training.py\", line 2381, in predict_step\n        return self(x, training=False)\n    File \"/Users/danielporras/Musica/new_env_3_10/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/danielporras/Musica/new_env_3_10/lib/python3.10/site-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_14\" is incompatible with the layer: expected shape=(None, 40, 174, 1), found shape=(32, 26, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "# Define the directory with the test songs\n",
    "test_dir = '/Users/danielporras/Musica/music_import/test_songs'\n",
    "\n",
    "# Load and preprocess the songs\n",
    "test_songs, test_song_names = load_and_preprocess_songs(test_dir)\n",
    "\n",
    "# Use the loaded model to make predictions\n",
    "predictions = loaded_model.predict(test_songs)\n",
    "\n",
    "# Get the class with the highest probability\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Define the mapping from indices to class labels\n",
    "class_labels = ['happy_exciting', 'heavy_rock', 'sad_reflective']\n",
    "\n",
    "# Print the predicted classes along with the song names\n",
    "for song_name, predicted_class in zip(test_song_names, predicted_classes):\n",
    "    print(f'Song: {song_name}, Predicted class: {class_labels[predicted_class]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model can predict 10 different classes.\n"
     ]
    }
   ],
   "source": [
    "num_classes = loaded_model.output_shape[-1]\n",
    "print(f'The model can predict {num_classes} different classes.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RestoredOptimizer` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RestoredOptimizer`.\n",
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.RMSprop` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.RMSprop`.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load the model\n",
    "loaded_model = load_model('/Users/danielporras/Musica/music_x/best_model.h7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test using scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction and data saving completed.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import librosa\n",
    "import numpy as np\n",
    "from pydub import AudioSegment\n",
    "import traceback\n",
    "\n",
    "# Define the function to extract MFCC features from an audio file\n",
    "def extract_features(file_path, num_segments=5, max_pad_length=174):\n",
    "    try:\n",
    "        audio = AudioSegment.from_file(file_path)\n",
    "        audio = audio.set_frame_rate(44100).set_channels(1)\n",
    "        audio.export(\"temp.wav\", format=\"wav\")\n",
    "        y, sr = librosa.load('temp.wav', sr=44100)\n",
    "\n",
    "        if len(y) < 30 * sr:\n",
    "            y = np.pad(y, int(np.ceil((30 * sr - len(y)) / 2)), mode='reflect')\n",
    "        y = y[int(len(y) / 2 - 15 * sr):int(len(y) / 2 + 15 * sr)]\n",
    "\n",
    "        mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=40)\n",
    "        if mfccs.shape[1] > max_pad_length:\n",
    "            mfccs = mfccs[:, :max_pad_length]\n",
    "        else:\n",
    "            padding = max_pad_length - mfccs.shape[1]\n",
    "            mfccs = np.pad(mfccs, ((0, 0), (0, padding)), mode='constant')\n",
    "\n",
    "        os.remove(\"temp.wav\")\n",
    "        return mfccs\n",
    "    except Exception as e:\n",
    "        print(f\"Error encountered while parsing file: {file_path}\")\n",
    "        print(traceback.format_exc())\n",
    "        return None\n",
    "\n",
    "# Path to the directory containing the audio files for prediction\n",
    "base_dir = '/Users/danielporras/Musica/musica_analysis/music_files/test_songs'\n",
    "features, song_names = [], []\n",
    "\n",
    "# Extract features for each audio file\n",
    "for file_name in os.listdir(base_dir):\n",
    "    if file_name.endswith('.mp3') or file_name.endswith('.m4a'):\n",
    "        file_path = os.path.join(base_dir, file_name)\n",
    "        file_features = extract_features(file_path)\n",
    "        if file_features is not None:\n",
    "            features.append(file_features.tolist())  # Convert numpy array to list for JSON serialization\n",
    "            song_names.append(file_name)\n",
    "\n",
    "if features:\n",
    "    # Save the features and song names for later prediction\n",
    "    data = {\n",
    "        \"features\": features,\n",
    "        \"song_names\": song_names\n",
    "    }\n",
    "    \n",
    "    with open('data_unlabeled.json', 'w') as fp:\n",
    "        json.dump(data, fp)\n",
    "    print(\"Feature extraction and data saving completed.\")\n",
    "else:\n",
    "    print(\"No features were extracted. Check the audio files and extraction process.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n",
      "watermarked_AEROPLANES_Groovy_Town_instrumental_2_31 copy.mp3: heavy_rock\n",
      "watermarked_Music_City_Reggae_Squad_Steel_Pan_Island_instrumental_2_36.mp3: sad_reflective\n",
      "Buscando-el-Son-no-voice_AdobeStock_709714291_preview copy.m4a: happy_exciting\n",
      "watermarked_Music_City_Reggae_Squad_Steel_Pan_Island_instrumental_2_36 copy.mp3: sad_reflective\n",
      "watermarked_LNDO_Just_Look_Up_background_vocals_2_45 copy.mp3: heavy_rock\n",
      "watermarked_Jed_Stark_Holidaze_instrumental_2_03.mp3: heavy_rock\n",
      "watermarked_Material_Gurl_The_Happiest_Memories_instrumental_1_56.mp3: heavy_rock\n",
      "Spanish-Summer-Dance_AdobeStock_452607663_preview copy.m4a: happy_exciting\n",
      "watermarked_Reveille_Go_For_It_instrumental_2_48 copy.mp3: heavy_rock\n",
      "watermarked_Tiger_Gang_Hotpants_instrumental_1_20.mp3: heavy_rock\n",
      "watermarked_PALA_Imagination_background_vocals_3_08 copy.mp3: sad_reflective\n",
      "FEEL-GOOD-HAPPY-WORLD_AdobeStock_537914173_preview copy.m4a: happy_exciting\n",
      "watermarked_Reveille_Go_For_It_instrumental_2_48.mp3: heavy_rock\n",
      "watermarked_Material_Gurl_The_Happiest_Memories_instrumental_1_56 copy.mp3: heavy_rock\n",
      "watermarked_PALA_Imagination_background_vocals_3_08.mp3: sad_reflective\n",
      "Buscando-el-Son-no-voice_AdobeStock_709714291_preview.m4a: happy_exciting\n",
      "CHILL-SALSA-GROOVE-(PALOMA)_AdobeStock_612913416_preview.m4a: happy_exciting\n",
      "Spanish-Summer-Dance_AdobeStock_452607663_preview.m4a: happy_exciting\n",
      "watermarked_Cast_Of_Characters_Reggae_Beach_instrumental_2_42.mp3: heavy_rock\n",
      "watermarked_Tiger_Gang_Hotpants_instrumental_1_20 copy.mp3: heavy_rock\n",
      "watermarked_Allex_Black_Water_background_vocals_3_02.mp3: heavy_rock\n",
      "watermarked_Cody_Martin_Petalstone_background_vocals_3_15 copy.mp3: heavy_rock\n",
      "watermarked_AEROPLANES_Groovy_Town_instrumental_2_31.mp3: heavy_rock\n",
      "watermarked_LNDO_Just_Look_Up_background_vocals_2_45.mp3: heavy_rock\n",
      "watermarked_Reveille_Autumnal_Dreams_instrumental_3_28 copy.mp3: heavy_rock\n",
      "watermarked_Allex_Black_Water_background_vocals_3_02 copy.mp3: heavy_rock\n",
      "2017-09-30_-_Death_Note_Tribute_-_David_Fesliyan copy 4.mp3: heavy_rock\n",
      "watermarked_Cast_Of_Characters_Reggae_Beach_instrumental_2_42 copy.mp3: heavy_rock\n",
      "watermarked_Reveille_Autumnal_Dreams_instrumental_3_28.mp3: heavy_rock\n",
      "FEEL-GOOD-HAPPY-WORLD_AdobeStock_537914173_preview.m4a: happy_exciting\n",
      "watermarked_Jed_Stark_Holidaze_instrumental_2_03 copy.mp3: heavy_rock\n",
      "CHILL-SALSA-GROOVE-(PALOMA)_AdobeStock_612913416_preview copy.m4a: happy_exciting\n",
      "watermarked_Cody_Martin_Petalstone_background_vocals_3_15.mp3: heavy_rock\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load the features from the JSON file\n",
    "with open('/Users/danielporras/Musica/musica_analysis/models/data_unlabeled.json', 'r') as fp:\n",
    "    data = json.load(fp)\n",
    "features = np.array(data[\"features\"])\n",
    "\n",
    "# Load the scaler and transform the features\n",
    "with open('/Users/danielporras/Musica/musica_analysis/models/scaler.pkl', 'rb') as f:\n",
    "    scaler = pickle.load(f)\n",
    "features_flattened = features.reshape(features.shape[0], -1)\n",
    "features_normalized = scaler.transform(features_flattened)\n",
    "features_normalized = features_normalized.reshape(features.shape)\n",
    "\n",
    "# Load the model\n",
    "model_path = '/Users/danielporras/Musica/music_x/best_model.h8'\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "# Predict the classes of the songs\n",
    "predictions_prob = model.predict(features_normalized)\n",
    "predictions = np.argmax(predictions_prob, axis=1)\n",
    "\n",
    "# Map predictions to class names\n",
    "class_names = ['happy_exciting', 'heavy_rock', 'sad_reflective']\n",
    "predicted_classes = [class_names[i] for i in predictions]\n",
    "\n",
    "# Print the predicted class for each song\n",
    "for song_name, predicted_class in zip(data[\"song_names\"], predicted_classes):\n",
    "    print(f\"{song_name}: {predicted_class}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_env_3_10",
   "language": "python",
   "name": "new_env_3_10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
